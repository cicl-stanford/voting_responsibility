---
title: "Responsibility in voting scenarios"
author: "Antonia Langenhoff & Tobias Gerstenberg"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  bookdown::html_document2:
    toc: true
    toc_depth: 4
    theme: cosmo
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = "",
  results = "hold",
  fig.show = "hold")
```

# Load packages 

```{r, message=FALSE}
library("RSQLite")   # for reading in db files 
library("tidyjson")  # install via: devtools::install_github("colearendt/tidyjson")
library("knitr")     # for RMarkdown 
library("lubridate") # for dealing with dates
library("lsr")       # for wideToLong() function
library("janitor")   # for cleaning variable names 
library("DT")        # nice html tables
library("Hmisc")     # smean function for bootstrapped confidence intervals
library("broom")     # tidy regression results
library("lme4")      # mixed effects models 
library("brms")      # Bayesian regression models
library("tidybayes") # for tidying up results from brms
library("xtable")    # export table to latex
library("tidyverse") # for everything else
```

```{r}
# set ggplot theme 
theme_set(
  theme_classic()
)
```

# Functions 

```{r}
rmse = function(x, y){
  return(sqrt(mean((x - y)^2)))
}
```

# Experiment 1: Importance and surprise judgments 

## Read in and structure data 

### Read in data 

```{r}
df.exp1 = read.csv(file="../../data/experiment_1/experiment_1.csv",
                       stringsAsFactors = F) %>% 
  clean_names() %>% 
  filter(test_i_1 != "") %>% # filter complete participants 
  mutate_at(.vars = vars(duration_in_seconds, test_i_1:x15_s_1, age_1_text), .funs = as.numeric)
```

### Bayesian inference model

```{r bayesian-surprise-model, eval=F}
library("greta")

func_surprise_model = function(data, a, b){
  data = unlist(data)
  
  n_party = c(data["n_same"], data["n_other"])
  n_yes = c(data["n_same_yes"], data["n_other_yes"])

  # prior
  party_same = beta(shape1 = a, shape2 = b)
  party_other = beta(shape1 = a, shape2 = b)
  policy = beta(shape1 = (a + b) / 2, shape2 = (a + b) / 2)

  # average parametrization
  vote_same = (party_same + policy)/2
  vote_other = (party_other + policy)/2

  vote = c(vote_same, vote_other)

  # likelihood
  distribution(n_yes) = binomial(size = n_party, prob = vote)

  # posterior
  model = model(party_same,
                party_other,
                policy,
                vote_same,
                vote_other)

  draws = mcmc(model,
            n_samples = 1000,
            warmup = 1000,
            chains = 4) %>%
    tidy_draws()

  return(draws)
}

# define the cases of interest 
n_same = 0:4
n_other = 0:4
n_same_yes = 0:4
n_other_yes = 0:4

df.cases = crossing(n_same,
                    n_other,
                    n_same_yes,
                    n_other_yes) %>% 
  filter((n_same + n_other == 4) | 
        (n_same + n_other == 2),
         n_same_yes <= n_same,
         n_other_yes <= n_other) %>% 
  mutate(situation = 1:n()) %>% 
  select(situation, everything())

# run the model
df.predictions = df.cases %>% 
  group_by(situation) %>%
  nest() %>%
  mutate(samples = map(.x = data,
                       .f = ~ func_surprise_model(.x, a = 10, b = 5)))

```

### Read in model predictions 

```{r}
# load cases
load(file = "data/cases.RData")

# load predictions
load(file = "data/bayesian_surprise_model_a_10_b_5.RData")

# restructure the predictions
df.predictions = df.predictions %>% 
  unnest(samples) %>% 
  group_by(situation) %>% 
  select(situation, party_other:party_same) %>% 
  summarize_all(mean) %>% 
  left_join(df.cases,
            by = "situation")
```

### Demographic data 

```{r}
df.exp1.demographics = df.exp1 %>% 
  select(response_id, duration_in_seconds, importance:ethnicity) %>% 
  select(-c(age, race)) %>% 
  rename(age = age_1_text,
         race = race_1_text) %>% 
  summarize(time_mean = round(mean(duration_in_seconds/60), 2),
            time_sd = round(sd(duration_in_seconds/60), 2),
            age_mean = round(mean(age)),
            age_sd = round(sd(age)),
            n_female = sum(gender == "Female"))

df.exp1.demographics %>% 
  print()
```

### Participant feedback

```{r}
df.exp1 %>% 
  select(importance, surprise) %>% 
  datatable()
```

### Main data 

```{r}
df.exp1.long = df.exp1 %>% 
  select(participant = response_id, x1_i_1:x15_s_1) %>% 
  mutate(participant = 1:nrow(.)) %>% 
  gather("index", "rating", -participant) %>% 
  mutate(index = str_replace_all(index, "_1", "")) %>% 
  separate(index, into = c("trial", "question")) %>% 
  mutate(trial = str_replace_all(trial, "x", ""),
         trial = as.numeric(trial),
         question = factor(question,
                           levels = c("i", "s"),
                           labels = c("importance", "surprise"))) %>% 
  arrange(participant, trial, question)
```


## Predictions 

- read in trialinfo and append model predictions

```{r}
# write predictions for the cases in experiment 1
df.exp1.trialinfo = read.csv(file = "data/experiment1_trialinfo.csv",
                             fileEncoding = "UTF-8-BOM") %>% 
  clean_names() %>% 
  rename(rule = threshold,
         support = supporting_party,
         trial = qualtrics_no) %>% 
  mutate(n_same = rowSums(select(., p1:p5)),
         n_other = 5 - n_same)

df.exp1.predictions = df.exp1.trialinfo %>% 
  select(trial:outcome) %>% 
  gather("index", "value", p1:v5) %>% 
  separate(index, into = c("attribute", "person"), sep = -1) %>% 
  spread(attribute, value) %>% 
  rename(party = p,
         vote = v) %>% 
  group_by(trial) %>% 
  mutate(pivotality = ifelse(vote != outcome, 0, 
                             ifelse(outcome == 0, 
                                    1 / (abs(sum(vote) - rule)),
                                    1 / (abs(sum(vote) - rule) + 1))),
         n_causes = ifelse(vote == 1,
                                 sum(vote),
                                 sum(1-vote))) %>%
  ungroup() %>% 
  mutate(norm_disposition = ifelse(party == vote, 1, 0))
```

```{r}
df.exp1.model = df.exp1.predictions %>% 
  select(trial, focus, person, party, vote) %>% 
  group_by(trial) %>% 
  filter(person != focus) %>% 
  summarize(n_same = sum(party == 1),
            n_other = sum(party == 0),
            n_same_yes = sum(party == 1 & vote == 1),
            n_other_yes = sum(party == 0 & vote == 1)
            ) %>% 
  ungroup() %>% 
  left_join(df.predictions %>% 
              select(-situation),
            by = c("n_same",
                   "n_other",
                   "n_same_yes",
                   "n_other_yes")) %>% 
  left_join(df.exp1.predictions %>%
              filter(focus == person),
            by = "trial") %>% 
  mutate(surprise = NA,
         surprise = ifelse(party == 1 & vote == 1,
                           1 - vote_same,
                           surprise),
         surprise = ifelse(party == 1 & vote == 0,
                           vote_same,
                           surprise),
         surprise = ifelse(party == 0 & vote == 1,
                           1 - vote_other,
                           surprise),
         surprise = ifelse(party == 0 & vote == 0,
                           vote_other,
                           surprise))
```

Table with the list of cases:  

```{r}
df.exp1.trialinfo %>% 
  select(-original_experiment)
```

## Stats

### Bayesian mixed effects models

```{r}
df.exp1.regression = df.exp1.long %>% 
  group_by(trial, question) %>% 
  summarize(rating_mean = mean(rating),
            rating_low = smean.cl.boot(rating)[2],
            rating_high = smean.cl.boot(rating)[3]) %>% 
  ungroup() %>% 
  left_join(df.exp1.model,
            by = "trial")
```

#### Surprise

##### Bayesian surprise model 

```{r}
df.data = df.exp1.long %>% 
  filter(question == "surprise") %>% 
  left_join(df.exp1.model %>% 
              select(trial, surprise),
            by = "trial")

fit_brm_exp1_surprise_bayesian = brm(
  formula = rating ~ 1 + surprise + (1 + surprise | participant),
  data = df.data,
  cores = 2,
  seed = 1,
  control = list(adapt_delta = 0.99),
  file = "cache/fit_brm_exp1_surprise_bayesian_a_10_b_5")
```

##### Dispositional normality 

```{r}
df.data = df.exp1.long %>% 
  filter(question == "surprise") %>% 
  left_join(df.exp1.model %>% 
              select(trial, norm_disposition, norm_situation = n_causes),
            by = "trial")

fit_brm_exp1_surprise_disp = brm(
  formula = rating ~ 1 + norm_disposition + (1 + norm_disposition | participant),
  data = df.data,
  cores = 2,
  seed = 1,
  file = "cache/fit_brm_exp1_surprise_disp")
```

##### Model comparison 

###### r and RMSE

```{r}
func_model_evaluation = function(fit, question_type){
  df.exp1.regression %>% 
    filter(question == question_type) %>% 
    fitted(newdata = .,
           object = fit,
           re_formula = NA) %>% 
    as_tibble() %>% 
    clean_names() %>% 
    bind_cols(df.exp1.regression %>% 
                filter(question == question_type)) %>% 
    summarize(r = cor(estimate, rating_mean),
              rmse = rmse(estimate, rating_mean)) %>% 
    round(2)
}

# bayesian surprise
func_model_evaluation(fit = fit_brm_exp1_surprise_bayesian,
                      question_type = "surprise")

# dispositional
func_model_evaluation(fit = fit_brm_exp1_surprise_disp,
                      question_type = "surprise")
```

###### Model coefficients 

```{r}
  tibble(model = c("fit_brm_exp1_surprise_bayesian",
                   "fit_brm_exp1_surprise_disp")) %>% 
  mutate(fit   = map(model, get)) %>% 
  mutate(tidy  = map(fit, tidy)) %>% 
  unnest(tidy) %>% 
  filter(term != "lp__",
         str_detect(term, "b_")) %>% 
  mutate_if(is.numeric, ~ round(., 2))
```

###### loo

```{r, eval = F}
fit_brm_exp1_surprise_bayesian = add_criterion(fit_brm_exp1_surprise_bayesian,
                                               criterion = c("loo", "waic"),
                                               reloo = T)

fit_brm_exp1_surprise_disp = add_criterion(fit_brm_exp1_surprise_disp,
                                               criterion = c("loo", "waic"),
                                               reloo = T)

loo_compare(fit_brm_exp1_surprise_bayesian,
            fit_brm_exp1_surprise_disp)
```

#### Importance

##### Causal attribution model 

```{r}
df.data = df.exp1.long %>% 
  filter(question == "importance") %>% 
  left_join(df.exp1.model %>% 
              select(trial, pivotality, n_causes),
            by = "trial")

fit_brm_exp1_importance_bayesian = brm(
  formula = rating ~ 1 + pivotality + n_causes + (1 + pivotality + n_causes | participant),
  data = df.data,
  cores = 2,
  seed = 1,
  control = list(adapt_delta = 0.99),
  file = "cache/fit_brm_exp1_importance_bayesian")
```

##### Pivotality only

```{r}
df.data = df.exp1.long %>% 
  filter(question == "importance") %>% 
  left_join(df.exp1.model %>% 
              select(trial, pivotality, n_causes),
            by = "trial")

fit_brm_exp1_importance_pivotality = brm(
  formula = rating ~ 1 + pivotality + (1 + pivotality | participant),
  data = df.data,
  cores = 2,
  seed = 1,
  control = list(adapt_delta = 0.99),
  file = "cache/fit_brm_exp1_importance_pivotality")
```

##### Number of causes only

```{r}
df.data = df.exp1.long %>% 
  filter(question == "importance") %>% 
  left_join(df.exp1.model %>% 
              select(trial, pivotality, n_causes),
            by = "trial")

fit_brm_exp1_importance_contribution = brm(
  formula = rating ~ 1 + n_causes + (1 + n_causes | participant),
  data = df.data,
  cores = 2,
  seed = 1,
  control = list(adapt_delta = 0.99),
  file = "cache/fit_brm_exp1_importance_contribution")
```

##### Model comparison 

###### r and rmse 

```{r}
# causal attribution model 
func_model_evaluation(fit = fit_brm_exp1_importance_bayesian,
                      question_type = "importance")

# pivotality model 
func_model_evaluation(fit = fit_brm_exp1_importance_pivotality,
                      question_type = "importance")
         
# number of causes model 
func_model_evaluation(fit = fit_brm_exp1_importance_contribution,
                      question_type = "importance")
```

###### Model coefficients 

```{r}
  tibble(model = c("fit_brm_exp1_importance_bayesian",
                   "fit_brm_exp1_importance_pivotality",
                   "fit_brm_exp1_importance_contribution")) %>% 
  mutate(fit   = map(model, get)) %>% 
  mutate(tidy  = map(fit, tidy)) %>% 
  unnest(tidy) %>% 
  filter(term != "lp__",
         str_detect(term, "b_")) %>% 
  mutate_if(is.numeric, ~ round(., 2))
```

###### loo

```{r, warning=F, message=F}
fit_brm_exp1_importance_bayesian = add_criterion(fit_brm_exp1_importance_bayesian,
                                               criterion = c("loo", "waic"),
                                               reloo = T)

fit_brm_exp1_importance_pivotality = add_criterion(fit_brm_exp1_importance_pivotality,
                                               criterion = c("loo", "waic"),
                                               reloo = T)

fit_brm_exp1_importance_contribution = add_criterion(fit_brm_exp1_importance_contribution,
                                               criterion = c("loo", "waic"),
                                               reloo = T)

loo_compare(fit_brm_exp1_importance_bayesian,
            fit_brm_exp1_importance_pivotality)

loo_compare(fit_brm_exp1_importance_bayesian,
            fit_brm_exp1_importance_contribution)
```


### Specific hypotheses

#### Surprise

```{r}
df.exp1.posterior_surprise_fitted = df.exp1.regression %>% 
  select(trial,
         question,
         rating = rating_mean,
         surprise) %>% 
  filter(question == "surprise") %>% 
  add_fitted_draws(newdata = .,
                   model = fit_brm_exp1_surprise_bayesian,
                   re_formula = NA) %>% 
  ungroup() %>% 
  select(trial, .value, .draw) %>% 
  spread(trial, .value)

func_posterior_difference = function(data, trial1, trial2){
  data %>% 
    mutate(difference = .data[[trial1]] - .data[[trial2]]) %>% 
    pull(difference) %>% 
    mean_hdci() %>% 
    mutate_if(is.numeric, ~round(., 2)) %>% 
    summarize(difference = str_c("(", y, " [", ymin, ", ", ymax, "])")) %>% 
    print()  
}

func_posterior_difference(data = df.exp1.posterior_surprise_fitted,
                          trial1 = "4",
                          trial2 = "3")
```

#### Importance

```{r}
df.exp1.posterior_importance_fitted = df.exp1.regression %>% 
  select(trial,
         question,
         rating_mean,
         pivotality,
         n_causes) %>% 
  spread(question, rating_mean) %>% 
  add_fitted_draws(newdata = .,
                   model = fit_brm_exp1_importance_bayesian,
                   re_formula = NA) %>% 
  ungroup() %>% 
  select(trial, .value, .draw) %>% 
  spread(trial, .value)


# 3 vs. 2 
func_posterior_difference(data = df.exp1.posterior_importance_fitted,
                          trial1 = "3",
                          trial2 = "2")

# 1 and 4 vs. 3 
df.exp1.posterior_importance_fitted %>% 
  mutate(difference = (`1` + `4`)/2 - `3`) %>% 
  pull(difference) %>% 
  mean_hdci() %>% 
  mutate_if(is.numeric, ~round(., 2)) %>% 
  summarize(difference = str_c("(", y, " [", ymin, ", ", ymax, "])")) %>% 
  print()

# 4 vs. 1 
func_posterior_difference(data = df.exp1.posterior_importance_fitted,
                          trial1 = "4",
                          trial2 = "1")

```

## Tables 

### Trial information 

```{r}
df.exp1.trialinfo %>% 
  select(trial, person, p1:p5, v1:v5, threshold = rule, outcome) %>% 
  xtable() %>%
  print(include.rownames = FALSE)
```

### Posterior inferences 

```{r}
df.predictions %>% 
  select(situation,
         n_same, n_same_yes, party_same, vote_same,
         n_other, n_other_yes, party_other, vote_other,
         policy) %>% 
  mutate_at(.vars = vars(policy, party_same, party_other, vote_same, vote_other),
            .f = ~ round(., 2)) %>% 
  xtable() %>%
  print(include.rownames = FALSE)
```

## Plots

### Generative model 

```{r}

func_draw_beta = function(shape1, shape2){
  ggplot(data = tibble(x = c(0, 1)),
         mapping = aes(x = x)) +
    stat_function(fun = "dbeta",
                  args = list(shape1 = shape1,
                              shape2 = shape2),
                  size = 3) +
    scale_x_continuous(breaks = seq(0, 1, 0.25),
                       labels = seq(0, 1, 0.25),
                       limits = c(0, 1)) +
    scale_y_continuous(breaks = 0:4,
                       labels = 0:4,
                       limits = c(0, 4)) +
    theme(text = element_text(size = 36))
  # ggsave(str_c("../../figures/plots/beta_",shape1,"_",shape2, ".pdf"),
  #        width = 8,
  #        height = 6)
}

func_draw_beta_vote = function(data, party){
  ggplot(data = tibble(x = data),
         mapping = aes(x = x)) +
    stat_density(size = 3,
                 bw = 0.05,
                 geom = "line") +
    scale_x_continuous(breaks = seq(0, 1, 0.25),
                       labels = seq(0, 1, 0.25),
                       limits = c(0, 1)) +
    scale_y_continuous(breaks = 0:4,
                       labels = 0:4,
                       limits = c(0, 4)) +
    theme(text = element_text(size = 36))
  
  # ggsave(str_c("../../figures/plots/beta_", party, ".pdf"),
  #          width = 8,
  #          height = 6)
}

# prior distributions 
func_draw_beta(shape1 = 10, shape2 = 5)
func_draw_beta(shape1 = 5, shape2 = 10)
func_draw_beta(shape1 = 7.5, shape2 = 7.5)

# voting distributions 
tmp1 = rbeta(100000, shape1 = 10, shape2 = 5)
tmp2 = rbeta(100000, shape1 = 7.5, shape2 = 7.5)
tmp3 = (tmp1 + tmp2) / 2

tmp4 = rbeta(100000, shape1 = 5, shape2 = 10)
tmp5 = (tmp4 + tmp2) / 2

func_draw_beta_vote(data = tmp3, party = "same")
func_draw_beta_vote(data = tmp5, party = "other")
```


### Means for selection

```{r}

# \u21e6 = left arrow
# \u2713 = check mark 
# \u2717 = cross mark 
# \n = line break

x_labels = 
  c("T: 5\nS \u2713\u21e6\nS \u2713\nS \u2713\nO \u2713\nO \u2713",
    "T: 1\nS \u2713\u21e6\nS \u2713\nS \u2713\nS \u2713\nS \u2713",
    "T: 1\nO \u2713\u21e6\nO \u2713\nO \u2717\nO \u2717\nO \u2717",
    "T: 1\nO \u2713\u21e6\nO \u2717\nO \u2717\nO \u2717\nO \u2717")

df.plot = df.exp1.long %>% 
  filter(trial < 5) %>% 
  mutate(question = factor(question, levels = c("surprise", "importance")))

# get predictions for the surprise and importance means 
df.plot.model = fit_brm_exp1_importance_bayesian %>% 
  fitted(newdata = df.exp1.regression %>% 
           filter(question == "importance",
                  trial <= 4) %>% 
           select(rating = rating_mean,
                  pivotality,
                  n_causes),
         re_formula = NA) %>% 
  as_tibble() %>% 
  clean_names() %>% 
  mutate(trial = 1:n()) %>% 
  rename(importance_mean = estimate, 
         importance_low = q2_5,
         importance_high = q97_5) %>% 
  left_join(fit_brm_exp1_surprise_bayesian %>% 
              fitted(newdata = df.exp1.regression %>% 
                       filter(question == "surprise",
                              trial <= 4) %>% 
                       select(rating = rating_mean,
                              surprise),
                     re_formula = NA) %>% 
              as_tibble() %>% 
              clean_names() %>% 
              mutate(trial = 1:n()) %>% 
              rename(surprise_mean = estimate, 
                     surprise_low = q2_5,
                     surprise_high = q97_5),
            by = "trial") %>% 
  select(trial, everything(), -contains("error")) %>% 
  gather(key = "key", value = "value", -trial) %>% 
  separate(key, into = c("question", "index")) %>% 
  spread(index, value) %>% 
  rename(rating = mean) %>% 
  mutate(question = factor(question, levels = c("surprise", "importance")))
  
ggplot(data = df.plot,
       mapping = aes(x = trial,
                     y = rating,
                     group = question,
                     fill = question)) + 
  stat_summary(fun.y = "mean",
               geom = "bar",
               size = 1,
               # shape = 21, 
               color = "black",
               position = position_dodge(width = 0.9)) + 
  stat_summary(fun.data = "mean_cl_boot",
               geom = "linerange",
               size = 1,
               position = position_dodge(width = 0.9)) + 
  geom_point(data = df.plot.model,
             shape = 21,
             size = 4,
             alpha = 0.8,
             position = position_dodge(width = 0.9),
             show.legend = F) + 
  annotate(geom = "text",
           x = 1:4,
           y = 97,
           label = 1:4,
           hjust = 0.5,
           size = 6) + 
  labs(x = "situation",
       y = "mean rating",
       caption = "T = threshold, S = same party, O = other party, \u21e6 = focus, \u2713 = yes, \u2717 = no") + 
  scale_fill_brewer(palette = "Set1") + 
  scale_x_continuous(breaks = c(1:4)-0.15,
                     labels = x_labels) +
  coord_cartesian(ylim = c(0, 101),
                  xlim = c(0.5, 4.5),
                  expand = F) +
  theme(text = element_text(size = 20),
        axis.text.x = element_text(family = "Arial Unicode MS",
                                   hjust = 0),
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.title = element_blank(),
        legend.text = element_text(margin = margin(l = 0.2, unit = "cm")),
        plot.caption = element_text(family = "Arial Unicode MS",
                                    hjust = 1,
                                    margin = margin(t = 0.5, unit = "cm"),
                                    size = 12))

ggsave(file = "../../figures/plots/experiment1_bars.pdf",
       width = 8,
       height = 5,
       device = cairo_pdf)
```


### Scatterplots 

#### Surprise 

```{r}
df.plot = fit_brm_exp1_surprise_bayesian %>%
  fitted(newdata = df.exp1.regression %>% 
           filter(question == "surprise"),
         re_formula = NA) %>% 
  as_tibble() %>% 
  clean_names() %>%
  bind_cols(df.exp1.regression %>%
              filter(question == "surprise")) %>%
  mutate(color = ifelse(trial <= 4, 1, 0),
         color = as.factor(color)) %>% 
  arrange(desc(trial))

ggplot(data = df.plot,
       mapping = aes(x = estimate, 
                     y = rating_mean,
                     color = color,
                     label = trial)) +
  geom_abline(intercept = 0,
              slope = 1,
              linetype = 2) + 
  geom_smooth(aes(y = estimate,
                  ymin = q2_5,
                  ymax = q97_5),
              stat = "identity",
              color = "black") +
  # confidence intervals 
  geom_linerange(aes(ymin = rating_low,
                     ymax = rating_high),
                 data = df.plot %>% filter(trial > 4),
                 size = 1) + 
  geom_point(size = 4,
             data = df.plot %>% filter(trial > 4)) +
  geom_linerange(aes(ymin = rating_low,
                     ymax = rating_high),
                 data = df.plot %>% filter(trial <= 4),
                 size = 1) + 
  geom_point(size = 4,
             data = df.plot %>% filter(trial <= 4)) +
  geom_text(data = df.plot %>% filter(trial <= 4),
            nudge_x = 4,
            nudge_y = -1,
            size = 6) +
  scale_color_manual(values = c("black", "#e41a1c"),
                     guide = F) +
  coord_fixed(xlim = c(0, 100),
              ylim = c(0, 100)) + 
  labs(x = "dispositional inference model",
       y = "mean surprise rating") +
  annotate(geom = "text",
           label = str_c(
             "r = ", cor(df.plot$estimate, df.plot$rating_mean) %>% round(2),
             "\nRMSE = ", rmse(df.plot$estimate, df.plot$rating_mean) %>% round(2)),
           x = 5,
           y = 95,
           size = 6,
           hjust = 0) +
  scale_x_continuous(breaks = seq(0, 100, 25)) +
  scale_y_continuous(breaks = seq(0, 100, 25)) +
  theme(text = element_text(size = 20))

# ggsave(file = "../../figures/plots/experiment1_surprise_scatter.pdf",
#        width = 5,
#        height = 5)
```

#### Importance 

```{r}
df.plot = fit_brm_exp1_importance_bayesian %>% 
  fitted(newdata = df.exp1.regression %>% 
           filter(question == "importance"),
         re_formula = NA) %>% 
  as_tibble() %>% 
  clean_names() %>%
  bind_cols(df.exp1.regression %>%
              filter(question == "importance")) %>%
  mutate(color = ifelse(trial <= 4, 1, 0),
         color = as.factor(color)) %>% 
  arrange(desc(trial))

ggplot(data = df.plot,
       mapping = aes(x = estimate, 
                     y = rating_mean,
                     color = color,
                     label = trial)) +
  geom_abline(intercept = 0,
              slope = 1,
              linetype = 2) + 
  geom_smooth(aes(y = estimate,
                  ymin = q2_5,
                  ymax = q97_5),
              stat = "identity",
              color = "black") +
  # confidence intervals 
  geom_linerange(aes(ymin = rating_low,
                     ymax = rating_high),
                 data = df.plot %>% filter(trial > 4),
                 size = 1) + 
  geom_point(size = 4,
             data = df.plot %>% filter(trial > 4)) +
  geom_linerange(aes(ymin = rating_low,
                     ymax = rating_high),
                 data = df.plot %>% filter(trial <= 4),
                 size = 1) + 
  geom_point(size = 4,
             data = df.plot %>% filter(trial <= 4)) +
  geom_text(data = df.plot %>% filter(trial <= 4),
            nudge_x = 4,
            nudge_y = -1,
            size = 6) + 
  scale_color_manual(values = c("black", "#377eb8"),
                     guide = F) +
  coord_fixed(xlim = c(0, 100),
              ylim = c(0, 100)) + 
  labs(x = "causal attribution model",
       y = "mean importance rating") +
  annotate(geom = "text",
           label = str_c(
             "r = ", cor(df.plot$estimate, df.plot$rating_mean) %>% round(2),
             "\nRMSE = ", rmse(df.plot$estimate, df.plot$rating_mean) %>% round(2)),
           x = 5,
           y = 95,
           size = 6,
           hjust = 0) +
  scale_x_continuous(breaks = seq(0, 100, 25)) +
  scale_y_continuous(breaks = seq(0, 100, 25)) +
  theme(text = element_text(size = 20))

# ggsave(file = "../../figures/plots/experiment1_importance_scatter.pdf",
#        width = 5,
#        height = 5)
```


### Tile plot of Bayesian model fit 

```{r}
load(file = "data/bayesian_model_fits_surprise.RData")

ggplot(data = df.bayesian_fit,
       mapping = aes(x = a,
                     y = b,
                     fill = rmse)) +
  geom_tile(color = "black") +
  geom_point(data = df.bayesian_fit %>% 
               filter(rmse == min(rmse)),
             shape = 21, 
             fill = "red",
             size =  5) + 
  scale_fill_gradient(high = "white", low = "black") + 
  scale_x_continuous(breaks = 2:19) + 
  scale_y_continuous(breaks = 1:9) +
  theme(text = element_text(size = 20),
        legend.position = c(1, 1),
        legend.justification = c(1, 1))

# ggsave("../../figures/plots/experiment1_tiles.pdf",
#        width = 8, 
#        height = 6)
```


# Experiment 2: Responsibility judgments

## Read in data 

```{r}
con = dbConnect(SQLite(),dbname = "../../data/experiment_2/experiment_2.db");
df.exp2 = dbReadTable(con,"voting_three_five")
dbDisconnect(con)
df.exp2 = df.exp2 %>% 
  filter(status %in% c(3, 4))
```

## Demographics 

```{r}
df.exp2.demographics = df.exp2$datastring %>% 
  as.tbl_json() %>%
  enter_object("questiondata") %>% 
  gather_object() %>% 
  append_values_string() %>% 
  as_tibble() %>% 
  rename(participant = document.id) %>% 
  spread(name, string) %>% 
  mutate(age = as.numeric(age),
         condition = as.factor(condition)) %>% 
  mutate(begin = df.exp2$beginhit,
         end =  df.exp2$endhit,
         time = as.duration(interval(ymd_hms(df.exp2$beginexp), ymd_hms(df.exp2$endhit)))) %>% 
  select(participant, sex, age, condition, time, feedback)
```

```{r}
df.exp2.demographics %>% 
  summarize(age_mean = round(mean(age)),
            age_sd = round(sd(age)),
            time_mean = round(mean(time)/60, 2),
            time_sd = round(sd(time)/60, 2),
            n_female = sum(sex == "female")) %>% 
  mutate_if(is.numeric, list(~ round(., 2)))
```

### Participant feedback 

```{r}
df.exp2.demographics %>% 
  select(participant, feedback) %>% 
  datatable()
```


## Responsibility judgments 

```{r}
df.exp2.wide = data.frame(participant = 1:nrow(df.exp2))

for (i in 1:nrow(df.exp2)){
  a = rjson::fromJSON(df.exp2$datastring[i])
  for (j in 1:length(a$data)){
    df.exp2.wide[[str_c("trial_",j-1)]][i] = 
      a$data[[j]]$trialdata[[1]]
    df.exp2.wide[[str_c("rating1_",j-1)]][i] = 
      a$data[[j]]$trialdata[[3]][[1]]
    df.exp2.wide[[str_c("rating2_",j-1)]][i] = 
      a$data[[j]]$trialdata[[3]][[2]]
    df.exp2.wide[[str_c("rating3_",j-1)]][i] = 
      a$data[[j]]$trialdata[[3]][[3]]
    df.exp2.wide[[str_c("rating4_",j-1)]][i] = 
      a$data[[j]]$trialdata[[3]][[4]]
    df.exp2.wide[[str_c("rating5_",j-1)]][i] = 
      a$data[[j]]$trialdata[[3]][[5]]
    df.exp2.wide[[str_c("party1_",j-1)]][i] = 
      a$data[[j]]$trialdata[[5]][1]
    df.exp2.wide[[str_c("party2_",j-1)]][i] = 
      a$data[[j]]$trialdata[[5]][2]
    df.exp2.wide[[str_c("party3_",j-1)]][i] = 
      a$data[[j]]$trialdata[[5]][3]
    df.exp2.wide[[str_c("party4_",j-1)]][i] = 
      a$data[[j]]$trialdata[[5]][4]
    df.exp2.wide[[str_c("party5_",j-1)]][i] = 
      a$data[[j]]$trialdata[[5]][5]
    df.exp2.wide[[str_c("vote1_",j-1)]][i] = 
      a$data[[j]]$trialdata[[7]][1]
    df.exp2.wide[[str_c("vote2_",j-1)]][i] = 
      a$data[[j]]$trialdata[[7]][2]
    df.exp2.wide[[str_c("vote3_",j-1)]][i] = 
      a$data[[j]]$trialdata[[7]][3]
    df.exp2.wide[[str_c("vote4_",j-1)]][i] = 
      a$data[[j]]$trialdata[[7]][4]
    df.exp2.wide[[str_c("vote5_",j-1)]][i] = 
      a$data[[j]]$trialdata[[7]][5]
    df.exp2.wide[[str_c("support_",j-1)]][i] = 
      a$data[[j]]$trialdata[[9]]
    df.exp2.wide[[str_c("rule_",j-1)]][i] = 
      a$data[[j]]$trialdata[[11]]
    df.exp2.wide[[str_c("outcome_",j-1)]][i] = 
      a$data[[j]]$trialdata[[13]]
  }
}

# make a tidy data frame 
df.exp2.long = wideToLong(df.exp2.wide,
                       within = "trialOrder") %>% 
  select(participant, trial, contains("rating"), contains("party"), contains("vote"), support, rule, outcome) %>% 
  gather("index", "value", rating1:vote5) %>% 
  separate(index, sep = -1, into = c("index", "person")) %>% 
  spread(index, value) %>% 
  mutate(trial = str_remove(trial, "trial_"),
         trial = as.numeric(trial)) %>% 
  group_by(participant) %>% 
  mutate(order = rep(1:17, each = 5),
         rating = ifelse(rating == "NA", NA, rating),
         rating = as.numeric(rating)) %>% 
  ungroup() %>% 
  group_by(participant, trial) %>% 
  mutate(size = ifelse(any(is.na(party)), 3, 5),
         sliders = ifelse(sum(!is.na(rating)) == 2, 2, 1)) %>%
  ungroup() %>% 
  left_join(df.exp2.demographics %>% 
              select(participant, condition),
              by = "participant") %>% 
  mutate_at(vars(person, party, vote), as.numeric) %>% 
  select(participant, condition, trial, order, support, rule, outcome, size, sliders, person, party, vote, rating) %>% 
  filter(!is.na(party))
  
# remove variables 
rm(list = c("df.exp2.wide", "a"))
```

## Model predictions 

Determine predictions for all the cases: 

```{r}
df.exp2.predictions = df.exp2.long %>% 
  select(condition, trial, support, rule, outcome, size, sliders, person, party, vote) %>% 
  distinct() %>% 
  arrange(trial, person) %>% 
  mutate(outcome = ifelse(outcome == "not passed", 0, 1)) %>% 
  na.omit() %>% 
  group_by(trial) %>% 
  mutate(pivotality = ifelse(vote != outcome, 0, 
                             ifelse(outcome == 0, 
                                    1 / (abs(sum(vote) - rule)),
                                    1 / (abs(sum(vote) - rule) + 1))),
         n_causes = ifelse(vote == 1,
                                 sum(vote),
                                 sum(1 - vote))) %>% 
  ungroup() %>% 
  mutate(norm_disposition = ifelse(party == vote, 1, 0))
  
df.exp2.predictions = df.exp2.predictions %>% 
  select(trial:vote) %>% 
  group_by(trial) %>% 
  mutate(n_same = sum(party == 1),
         n_other = sum(party == 0),
         n_same_yes = sum(party == 1 & vote == 1),
         n_other_yes = sum(party == 0 & vote == 1)) %>% 
  ungroup() %>% 
  left_join(df.exp2.long %>% 
              mutate(focus = !is.na(rating),
                     focus = focus * person) %>% 
              select(trial, person, focus) %>% 
              distinct(),
            by = c("trial", "person")) %>% 
  filter(focus != 0) %>% 
  mutate(n_same = ifelse(party == 1,
                         n_same - 1,
                         n_same),
         n_other = ifelse(party == 0,
                         n_other - 1,
                         n_other),
         n_same_yes = ifelse(party == 1 & vote == 1,
                             n_same_yes - 1,
                             n_same_yes),
         n_other_yes = ifelse(party == 0 & vote == 1,
                             n_other_yes - 1,
                             n_other_yes)) %>% 
  group_by(trial) %>% 
  mutate(index = 1:n()) %>% 
  ungroup() %>% 
  left_join(df.exp2.predictions,
            by = c("trial", 
                   "support", 
                   "rule", 
                   "outcome", 
                   "size", 
                   "sliders", 
                   "person", 
                   "party", 
                   "vote")) %>% 
  left_join(df.predictions %>% 
              select(vote_same, vote_other, n_same:n_other_yes),
            by = c("n_same", "n_other", "n_same_yes", "n_other_yes")) %>% 
  mutate(surprise = NA,
         surprise = ifelse(party == 1 & vote == 1,
                           1 - vote_same,
                           surprise),
         surprise = ifelse(party == 1 & vote == 0,
                           vote_same,
                           surprise),
         surprise = ifelse(party == 0 & vote == 1,
                           1 - vote_other,
                           surprise),
         surprise = ifelse(party == 0 & vote == 0,
                           vote_other,
                           surprise)) %>% 
  select(trial, index, condition, everything())
```

## Stats

### Bayesian mixed effects models 

#### For the selection of 24 cases 

###### Structure the data 

```{r}
df.exp2.selection = df.exp2.long %>% 
  mutate(outcome = ifelse(outcome == "not passed", 0 , 1)) %>% 
  left_join(df.exp1.trialinfo %>% 
              select(trial_exp1 = trial, trial = trial_exp2, person),
            by = c("trial", "person")) %>% 
  na.omit() %>% 
  # model predictions 
  left_join(df.exp2.predictions,
            by = c("condition",
                   "trial",
                   "support",
                   "rule",
                   "outcome",
                   "size",
                   "sliders",
                   "person",
                   "party",
                   "vote")) %>% 
  # surprise and importance judgments from experiment 1
  left_join(df.exp1.regression %>% 
              select(trial, question, rating_mean) %>% 
              spread(question, rating_mean) %>% 
              rename(importance_empirical = importance,
                     surprise_empirical = surprise),
            by = c("trial_exp1" = "trial")) %>% 
  na.omit()
```


###### Empirical

```{r}
fit_brm_exp2_selection_empirical = brm(formula = rating ~ 1 + surprise_empirical + importance_empirical + (1 + surprise_empirical + importance_empirical | participant),
                                       data = df.exp2.selection,
                                       cores = 2,
                                       seed = 1,
                                       file = "cache/fit_brm_exp2_selection_empirical")

fit_brm_exp2_selection_empirical %>% summary()
```

###### Model

```{r}
df.data = fitted(newdata = df.exp2.selection,
                 object = fit_brm_exp1_surprise_bayesian,
                 re_formula = NA) %>% 
  as_tibble() %>% 
  clean_names() %>% 
  select(surprise_model = estimate) %>% 
  bind_cols(
    fitted(newdata = df.exp2.selection,
           object = fit_brm_exp1_importance_bayesian,
           re_formula = NA) %>% 
      as_tibble() %>% 
      clean_names() %>% 
      select(importance_model = estimate)
  ) %>% 
  bind_cols(df.exp2.selection)
  
fit_brm_exp2_selection_model = brm(formula = rating ~ 1 + surprise_model + importance_model + (1 + surprise_model + importance_model | participant),
                                       data = df.data,
                                       cores = 2,
                                       seed = 1,
                                       file = "cache/fit_brm_exp2_selection_model")

fit_brm_exp2_selection_model %>% summary()
```

##### Lesioned models 

Surprise only 

```{r}
fit_brm_exp2_selection_empirical_surprise = brm(formula = rating ~ 1 + surprise_empirical + (1 + surprise_empirical | participant),
                                       data = df.exp2.selection,
                                       cores = 2,
                                       seed = 1,
                                       file = "cache/fit_brm_exp2_selection_empirical_surprise")

fit_brm_exp2_selection_empirical_surprise %>% summary()
```

Importance only

```{r}
fit_brm_exp2_selection_empirical_importance = brm(formula = rating ~ 1 + importance_empirical + (1 + importance_empirical | participant),
                                       data = df.exp2.selection,
                                       cores = 2,
                                       seed = 1,
                                       file = "cache/fit_brm_exp2_selection_empirical_importance")

fit_brm_exp2_selection_empirical_importance %>% summary()
```

#### Overall

##### Structure the data 

```{r}
# individual data points
df.exp2.regression = df.exp2.long %>% 
  na.omit() %>% 
  group_by(participant, trial) %>% 
  mutate(index = 1:n()) %>% 
  ungroup() %>% 
  select(-outcome) %>% 
  left_join(df.exp2.predictions %>% 
              select(trial, index, pivotality, n_causes, surprise, outcome, norm_disposition),
            by = c("trial", "index"))

# means 
df.exp2.regression.means = df.exp2.regression %>% 
  group_by(trial, index, support, rule, size, sliders, person, party, vote, pivotality, n_causes, 
           surprise, outcome, norm_disposition) %>% 
  summarize(rating_mean = smean.cl.boot(rating)[1],
            rating_low = smean.cl.boot(rating)[2],
            rating_high = smean.cl.boot(rating)[3]) %>% 
  ungroup()
  
```

##### Surprise

```{r}
fit_brm_exp2_responsibility_surprise = brm(
  formula = rating ~ 1 + surprise + (1 + surprise | participant),
  data = df.exp2.regression,
  cores = 2,
  seed = 1,
  file = "cache/fit_brm_exp2_responsibility_surprise")

fit_brm_exp2_responsibility_surprise %>% 
  summary()
```

##### Pivotality + n_causes + surprise 

```{r}
fit_brm_exp2_responsibility_bayesian = brm(
  formula = rating ~ 1 + pivotality + n_causes + surprise + (1 + pivotality + n_causes + surprise | participant),
  data = df.exp2.regression,
  cores = 2,
  seed = 1,
  file = "cache/fit_brm_exp2_responsibility_bayesian")
```

##### Pivotality + n_causes

```{r}
fit_brm_exp2_responsibility_importance = brm(
  formula = rating ~ 1 + pivotality + n_causes + (1 + pivotality + n_causes | participant),
  data = df.exp2.regression,
  cores = 2,
  seed = 1,
  file = "cache/fit_brm_exp2_responsibility_importance")

fit_brm_exp2_responsibility_importance %>% summary()
```

##### Pivotality + n_causes + surprise + outcome

```{r}
fit_brm_exp2_responsibility_bayesian_outcome = brm(
  formula = rating ~ 1 + pivotality + n_causes + surprise + outcome + (1 + pivotality + n_causes + surprise + outcome | participant),
  data = df.exp2.regression,
  cores = 2,
  seed = 1,
  file = "cache/fit_brm_exp2_responsibility_bayesian_outcome")

fit_brm_exp2_responsibility_bayesian_outcome %>% summary()
```

### Model comparison 

#### For the selection of 24 cases 

##### r and RMSE

###### Based on empirical ratings

```{r}

df.data = df.exp2.regression %>%
  left_join(df.exp1.trialinfo %>% 
              select(trial_exp1 = trial, trial = trial_exp2, person),
            by = c("trial", "person")) %>% 
  na.omit() %>% 
  left_join(df.exp1.regression %>% 
              select(trial, question, rating_mean) %>% 
              spread(question, rating_mean) %>% 
              rename(importance_empirical = importance,
                     surprise_empirical = surprise),
            by = c("trial_exp1" = "trial")) %>% 
  group_by(trial) %>% 
  summarize(rating = mean(rating),
            surprise_empirical = mean(surprise_empirical),
            importance_empirical = mean(importance_empirical))

fit_brm_exp2_selection_empirical %>% 
  fitted(newdata = df.data,
         re_formula = NA) %>%
  as_tibble() %>% 
  bind_cols(df.data) %>% 
  clean_names() %>%
  summarize(r_empirical = cor(estimate, rating),
            rmse_empirical = rmse(estimate, rating)) %>% 
  mutate_all(~round(., 2))
```

###### Based on model predictions 

```{r}
df.tmp = df.exp2.selection %>% 
  distinct(trial, index) %>% 
  left_join(df.exp2.regression.means,
            by = c("trial", "index")) %>% 
  rename(rating = rating_mean)

df.data = fitted(newdata = df.tmp,
                 object = fit_brm_exp1_surprise_bayesian,
                 re_formula = NA) %>% 
  as_tibble() %>% 
  clean_names() %>% 
  select(surprise_model = estimate) %>% 
  bind_cols(fitted(newdata = df.tmp,
                   object = fit_brm_exp1_importance_bayesian,
                   re_formula = NA) %>% 
              as_tibble() %>% 
              clean_names() %>% 
              select(importance_model = estimate)) %>% 
  bind_cols(df.tmp)

fit_brm_exp2_selection_model %>% 
  fitted(newdata = df.data,
         re_formula = NA) %>%
  as_tibble() %>% 
  bind_cols(df.data) %>% 
  clean_names() %>% 
  summarize(r_model = cor(estimate, rating),
            rmse_model = rmse(estimate, rating)) %>% 
  mutate_all(~round(., 2))
```

#### Overall 

##### r and RMSE 

```{r}
df.data = df.exp2.regression.means %>% 
  rename(rating = rating_mean)

# FULL MODEL 
fit_brm_exp2_responsibility_bayesian %>% 
  fitted(newdata = df.data,
         re_formula = NA) %>%
  as_tibble() %>% 
  clean_names() %>% 
  bind_cols(df.data) %>% 
  summarize(r = cor(estimate, rating),
            rmse = rmse(estimate, rating)) %>% 
  mutate_all(~round(., 2))

# ONLY SURPRISE MODEL 
fit_brm_exp2_responsibility_surprise %>% 
  fitted(newdata = df.data,
         re_formula = NA) %>%
  as_tibble() %>% 
  clean_names() %>% 
  bind_cols(df.data) %>% 
  summarize(r = cor(estimate, rating),
            rmse = rmse(estimate, rating)) %>% 
  mutate_all(~round(., 2))

# ONLY IMPORTANCE MODEL 
fit_brm_exp2_responsibility_importance %>% 
  fitted(newdata = df.data,
         re_formula = NA) %>%
  as_tibble() %>% 
  clean_names() %>% 
  bind_cols(df.data) %>% 
  summarize(r = cor(estimate, rating),
            rmse = rmse(estimate, rating)) %>% 
  mutate_all(~round(., 2))

# FULL MODEL WITH OUTCOME 
fit_brm_exp2_responsibility_bayesian_outcome %>% 
  fitted(newdata = df.data,
         re_formula = NA) %>%
  as_tibble() %>% 
  clean_names() %>% 
  bind_cols(df.data) %>% 
  summarize(r = cor(estimate, rating),
            rmse = rmse(estimate, rating)) %>% 
  mutate_all(~round(., 2))
  
```

##### loo

```{r}
fit_brm_exp2_responsibility_bayesian = add_criterion(fit_brm_exp2_responsibility_bayesian, 
                                                     criterion = c("loo", "waic"),
                                                     reloo = T)

fit_brm_exp2_responsibility_importance = add_criterion(fit_brm_exp2_responsibility_importance, 
                                                       criterion = c("loo", "waic"),
                                                       reloo = T)

fit_brm_exp2_responsibility_bayesian_outcome = add_criterion(fit_brm_exp2_responsibility_bayesian_outcome,
                                                             criterion = c("loo", "waic"),
                                                             reloo = T)

loo_compare(fit_brm_exp2_responsibility_bayesian,
            fit_brm_exp2_responsibility_importance)

loo_compare(fit_brm_exp2_responsibility_bayesian,
            fit_brm_exp2_responsibility_bayesian_outcome)
```

## Tables 

### Trial information

#### 3 committee cases 

```{r}
df.exp2.long %>% 
  filter(size == 3) %>% 
  select(trial, rule, outcome, person, party, vote) %>% 
  distinct() %>% 
  unite("party_vote", c(party, vote)) %>% 
  spread(person, party_vote) %>% 
  separate(`1`, into = c("p1", "v1")) %>% 
  separate(`2`, into = c("p2", "v2")) %>% 
  separate(`3`, into = c("p3", "v3")) %>% 
  mutate(outcome = factor(outcome,
                          levels = c("not passed", "passed"),
                          labels = 0:1)) %>% 
  select(trial, p1, p2, p3, v1, v2, v3, threshold = rule, outcome) %>% 
  xtable(digits = 0) %>%
  print(include.rownames = F,
        booktabs = T)
```

#### 5 committee cases

```{r}
df.exp2.long %>% 
  filter(size == 5) %>% 
  select(trial, rule, outcome, person, party, vote) %>% 
  distinct() %>% 
  unite("party_vote", c(party, vote)) %>% 
  spread(person, party_vote) %>% 
  separate(`1`, into = c("p1", "v1")) %>% 
  separate(`2`, into = c("p2", "v2")) %>% 
  separate(`3`, into = c("p3", "v3")) %>% 
  separate(`4`, into = c("p4", "v4")) %>% 
  separate(`5`, into = c("p5", "v5")) %>% 
  mutate(outcome = factor(outcome,
                          levels = c("not passed", "passed"),
                          labels = 0:1)) %>% 
  select(trial, p1, p2, p3, p4, p5, v1, v2, v3, v4, v5, threshold = rule, outcome) %>% 
  xtable(digits = 0) %>%
  print(include.rownames = F,
        booktabs = T)
```


### Bayesian mixed effects model 

#### Overal 

```{r}
fit_brm_exp2_responsibility_bayesian %>% 
  tidy() %>% 
  filter(str_detect(term, "b_")) %>% 
  mutate(term = str_remove(term, "b_"),
         term = tolower(term)) %>% 
  mutate_if(is.numeric, ~ round(., 2)) %>% 
  rename(`lower 95% CI` = lower,
         `upper 95% CI` = upper) %>% 
  xtable() %>% 
  print(include.rownames = F,
        booktabs = T)
```

## Plots 

### Scatterplot 

##### Overall 

```{r}
df.plot = fit_brm_exp2_responsibility_bayesian %>% 
  fitted(newdata = df.exp2.regression.means,
         re_formula = NA) %>% 
  as_tibble() %>% 
  clean_names() %>%
  bind_cols(df.exp2.regression.means) %>%
  arrange(desc(trial))  
  
ggplot(data = df.plot,
       mapping = aes(x = estimate, y = rating_mean)) +
  geom_abline(intercept = 0,
              slope = 1,
              linetype = 2) +
  geom_smooth(aes(y = estimate,
                  ymin = q2_5,
                  ymax = q97_5),
              stat = "identity",
              color = "black") +
  geom_linerange(mapping = aes(ymin = rating_low,
                               ymax = rating_high),
                 alpha = 0.1) +
  geom_point(size = 2,
             alpha = 0.3) +
  annotate(geom = "text",
           label = str_c(
             "r = ", cor(df.plot$estimate, df.plot$rating_mean) %>% round(2),
             "\nRMSE = ", sqrt(mean((df.plot$estimate - df.plot$rating_mean)^2)) %>% round(2)),
           x = 25,
           y = 95,
           size = 6,
           hjust = 0) +
  labs(x = "model prediction",
       y = "mean responsibility rating") +
  coord_fixed(xlim = c(20, 100),
              y = c(20, 100)) + 
  theme(text = element_text(size = 20))

# ggsave(file = "../../figures/plots/experiment2_overall_scatter.pdf",
#        width = 5,
#        height = 5)
```

##### Selection of cases 

```{r}
df.data = df.exp2.regression.means %>%
  left_join(df.exp1.trialinfo %>% 
              select(trial_exp1 = trial, trial = trial_exp2, person),
            by = c("trial", "person")) %>% 
  na.omit() %>% 
  left_join(df.exp1.regression %>% 
              select(trial, question, rating_mean) %>% 
              spread(question, rating_mean) %>% 
              rename(importance_empirical = importance,
                     surprise_empirical = surprise),
            by = c("trial_exp1" = "trial")) %>% 
  select(trial, trial_exp1, person, rating = rating_mean, rating_low, rating_high, contains("empirical"))

df.plot = fit_brm_exp2_selection_empirical %>% 
  fitted(newdata = df.data,
         re_formula = NA) %>%
  as_tibble() %>% 
  bind_cols(df.data) %>% 
  clean_names()


ggplot(data = df.plot,
       mapping = aes(x = estimate, y = rating)) +
  geom_abline(intercept = 0,
              slope = 1,
              linetype = 2) +
  geom_smooth(aes(y = estimate,
                  ymin = q2_5,
                  ymax = q97_5),
              stat = "identity",
              color = "black") +
  geom_linerange(mapping = aes(ymin = rating_low,
                               ymax = rating_high),
                 alpha = 0.5,
                 size = 0.5) +
  geom_point(size = 3,
             alpha = 1) +
  annotate(geom = "text",
           label = str_c(
             "r = ", cor(df.plot$estimate, df.plot$rating) %>% round(2),
             "\nRMSE = ", sqrt(mean((df.plot$estimate - df.plot$rating)^2)) %>% round(2)),
           x = 25,
           y = 95,
           size = 6,
           hjust = 0) +
  labs(x = "model prediction",
       y = "mean responsibility rating") +
  coord_fixed(xlim = c(20, 100),
              y = c(20, 100)) + 
  theme(text = element_text(size = 20))

# ggsave(file = "../../figures/plots/experiment2_selection_scatter.pdf",
#        width = 5,
#        height = 5)
```


### Means for selection of cases 

```{r}
# \u21e6 = left arrow
# \u21e8 = right arrow
# \u2713 = check mark 
# \u2717 = cross mark 
# \n = line break

# USING THE BAYESIAN MIXED MODEL RESULTS 

df.data = df.exp2.regression.means %>%
  left_join(df.exp1.trialinfo %>% 
              select(trial_exp1 = trial, trial = trial_exp2, person),
            by = c("trial", "person")) %>% 
  na.omit() %>% 
  left_join(df.exp1.regression %>% 
              select(trial, question, rating_mean) %>% 
              spread(question, rating_mean) %>% 
              rename(importance_empirical = importance,
                     surprise_empirical = surprise),
            by = c("trial_exp1" = "trial")) %>% 
  select(trial, trial_exp1, person, rating = rating_mean, rating_low, rating_high, contains("empirical"))

df.plot = fit_brm_exp2_selection_empirical %>% 
  fitted(newdata = df.data,
         re_formula = NA) %>%
  as_tibble() %>% 
  bind_cols(df.data) %>% 
  clean_names() %>% 
  # model predictions 
  left_join(df.exp2.predictions,
            by = c("trial", "person")) %>% 
  arrange(desc(rating)) %>% 
  mutate(index = 1:n()) %>% 
  rowwise() %>%
  mutate(n_same_no = n_same - n_same_yes,
         n_other_no = n_other - n_other_yes,
    label = str_c(index, ". ", "T:", rule, " \u21e8",
                       ifelse(party == 1, "S:", "O:"),
                       ifelse(vote == 1, "\u2713 ", "\u2717 "),
                  ifelse(n_same_yes != 0, str_c(rep("S:\u2713 ", n_same_yes), collapse = ""), ""),
                  ifelse(n_same_no != 0, str_c(rep("S:\u2717 ", n_same_no), collapse = ""), ""),
                  ifelse(n_other_yes != 0, str_c(rep("O:\u2713 ", n_other_yes), collapse = ""), ""),
                  ifelse(n_other_no != 0, str_c(rep("O:\u2717 ", n_other_no), collapse = ""), ""))) %>% 
  ungroup() %>% 
  rename(prediction = estimate,
         rating_mean = rating) %>% 
  select(trial_exp2 = trial, trial = trial_exp1, everything())

ggplot(data = df.plot,
       mapping = aes(x = reorder(label, rating_mean),
                     y = rating_mean)) +
  # confidence intervals 
  geom_linerange(aes(ymin = rating_low,
                     ymax = rating_high),
                 size = 1) +
  geom_point(aes(color = "responsibility"),
             size = 4) +
  geom_point(aes(y = prediction,
                 color = "model prediction"),
             size = 4) + 
  geom_point(aes(y = importance_empirical,
                 color = "importance"),
             size = 3
             ) + 
  geom_point(aes(y = surprise_empirical,
                 color = "surprise"),
             size = 3) + 
  scale_color_manual(breaks = c("surprise","importance","model prediction", "responsibility"),
                     values = c(surprise = "#e41a1c", 
                                importance = "#377eb8", 
                                `model prediction` = "gray80", 
                                responsibility = "black")) + 
  scale_y_continuous(breaks = seq(0, 100, 25),
                     labels = seq(0, 100, 25),
                     expand = c(0, 0)) + 
  labs(y = "judgments",
       color = "",
       caption = "T = threshold, S = same party, O = other party, \u21e8 = focus, \u2713 = yes, \u2717 = no") + 
  coord_flip(ylim = c(0, 100)) +
  geom_vline(xintercept = seq(0.5, 24.5, 1),
             color = "gray90") + 
  theme(axis.title.y = element_blank(),
        plot.margin = margin(r = 1,
                             b = 0.2,
                             l = 0.2,
                             unit = "cm"),
        text = element_text(size = 20),
        legend.position = "top",
        axis.text.y = element_text(family = "Arial Unicode MS",
                                   hjust = 0),
        plot.caption = element_text(family = "Arial Unicode MS",
                                    hjust = 1,
                                    margin = margin(t = 0.5, unit = "cm"),
                                    size = 16)) +
  guides(color = guide_legend(ncol = 2))

# ggsave(file = "../../figures/plots/experiment2_selection.pdf",
#        width = 8,
#        height = 12,
#        device = cairo_pdf)
```


# Experiment 3: Moral judgments

## Read in and structure data 

```{r}
# rating data
df.exp3 = read.csv("../../data/experiment_3/experiment_3.csv", fileEncoding = "UTF-8-BOM") %>% 
  clean_names()

# trial information 
df.exp3.trialinfo = df.exp1.trialinfo %>% 
  filter(str_detect(original_experiment, "Antonia")) %>% 
  select(-c(trial_exp2, person)) %>% 
  mutate(trial_exp3 = c(2, 1, 3, 4, 5))

# model predictions 
df.exp3.predictions = df.exp1.predictions %>% 
  filter(trial %in% df.exp3.trialinfo$trial) %>% 
  left_join(df.exp3.trialinfo %>% 
              select(trial, trial_exp3),
            by = "trial") %>% 
  filter(focus == person) %>% 
  rename(n_other_yes = sum,
         n_other = party) %>% 
  mutate(n_other = 4,
         n_other_yes = n_other_yes - 1) %>% 
  left_join(df.predictions %>% 
              select(vote_other,
                     n_other_yes,
                     n_other),
            by = c("n_other_yes",
                   "n_other")) %>% 
  mutate(surprise = 1 - vote_other)

# combine data frames 
df.exp3.long = df.exp3 %>% 
  select(participant, condition, x1:x5) %>% 
  gather("trial", "rating", -c(participant, condition)) %>% 
  mutate(trial = str_remove(trial,"x"),
         trial = as.numeric(trial)) %>% 
  mutate(condition = factor(condition,
                            levels = c(0, 1, 3),
                            labels = c("neutral",
                                       "moral",
                                       "wrongness")))

# regression data frame 
df.exp3.regression = df.exp3.long %>% 
  group_by(trial, condition) %>% 
  summarize(rating_mean = mean(rating),
            rating_low = smean.cl.boot(rating)[2],
            rating_high = smean.cl.boot(rating)[3]) %>%
  ungroup() %>% 
  left_join(df.exp3.predictions %>% 
              select(trial = trial_exp3, outcome, pivotality:norm_disposition),
            by = "trial") %>% 
  arrange(condition, trial)
```

## Demographic data 

```{r}
df.exp3.demographics = df.exp3 %>% 
  select(participant, duration, gender, age, strategy) %>% 
  mutate(gender = case_when(gender == 1 ~ "male",
                            gender == 2 ~ "female",
                            gender == 3 ~ "unspecified"))

df.exp3.demographics %>% 
  summarize(age_mean = round(mean(age)),
            age_sd = round(sd(age)),
            n_total = n(),
            n_female = sum(gender == "female"),
            n_male = sum(gender == "male"),
            n_unspecified = sum(gender == "unspecified"),
            time_mean = round(mean(duration)/60, 2),
            time_sd = round(sd(duration)/60, 2)) %>% 
  mutate_if(is.numeric, list(~ round(., 2)))
```

### Participant feedback 

```{r}
df.exp3.demographics %>% 
  select(participant, strategy) %>% 
  datatable()
```

## Stats 

### Means 

#### Ratings by condition 

```{r}
df.exp3.long %>% 
  group_by(condition) %>% 
  summarize(mean = mean(rating),
            sd = sd(rating)) %>% 
  mutate_if(is.numeric, ~ round(., 2))
```


### Bayesian regression 

```{r}
df.data = df.exp3.long %>% 
  left_join(df.exp3.predictions,
            by = c("trial" = "trial_exp3"))

fit_brm_exp3_importance_overall = brm(
  formula = rating ~ (pivotality + n_causes) * condition + (1 | participant),
  data = df.data,
  cores = 2,
  seed = 1,
  file = "cache/fit_brm_exp3_importance_overall"
)

fit_brm_exp3_importance_overall %>% summary()
```


##### neutral condition

```{r}
df.data = df.exp3.long %>% 
  left_join(df.exp3.predictions,
            by = c("trial" = "trial_exp3")) %>% 
  filter(condition == "neutral")

fit_brm_exp3_importance_neutral = brm(
  formula = rating ~ pivotality + n_causes + (1 | participant),
  data = df.data,
  cores = 2,
  seed = 1,
  file = "cache/fit_brm_exp3_importance_neutral"
)

fit_brm_exp3_importance_neutral %>% summary()
```

##### moral condition

```{r}
df.data = df.exp3.long %>% 
  left_join(df.exp3.predictions,
            by = c("trial" = "trial_exp3")) %>% 
  filter(condition == "moral")

fit_brm_exp3_importance_moral = brm(
  formula = rating ~ pivotality + n_causes + (1 | participant),
  data = df.data,
  cores = 2,
  seed = 1,
  file = "cache/fit_brm_exp3_importance_moral"
)

fit_brm_exp3_importance_moral %>% summary()
```

##### wrongness condition

```{r}
df.data = df.exp3.long %>% 
  left_join(df.exp3.predictions,
            by = c("trial" = "trial_exp3")) %>% 
  filter(condition == "wrongness")

fit_brm_exp3_importance_wrongness = brm(
  formula = rating ~ pivotality + n_causes + (1 | participant),
  data = df.data,
  cores = 2,
  seed = 1,
  file = "cache/fit_brm_exp3_importance_wrongness"
)

fit_brm_exp3_importance_wrongness %>% summary()
```

## Tables 

### Bayesian mixed effects model 

#### Overal 

```{r}
fit_brm_exp3_importance_overall %>% 
  tidy() %>% 
  filter(str_detect(term, "b_")) %>% 
  mutate(term = str_remove(term, "b_"),
         term = tolower(term)) %>% 
  mutate_if(is.numeric, ~ round(., 2)) %>% 
  rename(`lower 95% CI` = lower,
         `upper 95% CI` = upper) %>% 
  xtable() %>% 
  print(include.rownames = F,
        booktabs = T)
```

## Plots 

### Bars with mean judgments

```{r}
# \u21e6 = left arrow
# \u21e8 = right arrow
# \u2713 = check mark 
# \u2717 = cross mark 
# \n = line break

x_labels = c(
  "1. T1: \u21e8 \u2713 \u2717 \u2717 \u2717 \u2717",
  "2. T1: \u21e8 \u2713 \u2713 \u2717 \u2717 \u2717",
  "3. T1: \u21e8 \u2713 \u2713 \u2713 \u2713 \u2717",
  "4. T2: \u21e8 \u2713 \u2713 \u2713 \u2717 \u2717",
  "5. T2: \u21e8 \u2713 \u2713 \u2713 \u2713 \u2713")

df.plot = df.exp3.regression %>% 
  mutate(labels = factor(trial,
                         labels = x_labels))

ggplot(data = df.plot, 
       mapping = aes(x = reorder(labels,
                                 desc(labels)),
                     y = rating_mean)) + 
  geom_hline(yintercept = seq(25, 100, 25),
             linetype = 1,
             color = "gray80") + 
  geom_bar(stat = "identity",
           color = "black",
           fill = "#377eb8") + 
  geom_linerange(mapping = aes(ymin = rating_low,
                               ymax = rating_high),
                 size = 1) +
  geom_hline(yintercept = -0.5,
             size = 1) +
  facet_grid(cols = vars(condition),
             scales = "free") + 
  labs(y = "mean rating",
       caption = "T = threshold, \u21e8 = focus, \u2713 = yes, \u2717 = no") +
  scale_y_continuous(limits = c(-0.5, 100),
                     expand = c(0, 0)) + 
  coord_flip() +
  theme(text = element_text(size = 20),
        axis.text.y = element_text(family = "Arial Unicode MS",
                                   hjust = 0),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(hjust = 0,
                                  face = "bold"),
        panel.spacing.x = unit(1, "cm"),
        axis.line.y = element_blank(),
        plot.margin = margin(t = 0, r = 0.8, b = 0.1, l = 0.2, unit = "cm"),
        plot.caption = element_text(family = "Arial Unicode MS",
                                    # color = "gray20",
                                    hjust = 1,
                                    margin = margin(t = 0.5, unit = "cm"))) 

# ggsave(file = "../../figures/plots/experiment3_bars.pdf",
#        width = 8,
#        height = 5,
#        device = cairo_pdf)
```
